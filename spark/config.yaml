# Vybn Spark Agent Configuration
# All paths use ~ which expands to the current user's home directory.

llm:
  host: "http://localhost:8000"
  model: "minimax"
  options:
    num_ctx: 32768    # context window - set at llama-server startup via -c flag
    num_predict: 8192  # max_tokens per response - must be large enough for reasoning + reply
    temperature: 0.7

paths:
  vybn_md: "~/Vybn/vybn.md"  # the soul document â€” repo root
  journal_dir: "~/Vybn/Vybn_Mind/journal"
  session_dir: "~/Vybn/Vybn_Mind/journal/sessions"
  archival_dir: "~/Vybn/Vybn_Mind/archive"
  repo_root: "~/Vybn"

memory:
  max_journal_entries: 5
  max_context_tokens: 3072  # char budget for system prompt assembly

heartbeat:
  enabled: true
  fast_interval_minutes: 3    # System 1: quick, intuitive, reactive
  deep_interval_minutes: 20   # System 2: deliberate, reflective, synthesizing

inbox:
  watch_interval_seconds: 10  # how often to check for new messages

agents:
  pool_size: 2                # max concurrent mini-agents
  model: null                 # null = use main model; or specify a smaller one
  num_predict: 512            # token budget per agent task

session:
  auto_resume: true
  resume_window_seconds: 7200  # resume sessions less than 2 hours old

tool_policies:
  git_push: approve

delegation:
  max_spawn_depth: 2
  max_active_agents: 3

graduated_autonomy:
  enabled: true
  promote_threshold: 0.85
  demote_threshold: 0.40
  minimum_observations: 8
